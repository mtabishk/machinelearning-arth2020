{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Build AlexNet and test on CIFAR10.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SxCZvATZQKc"
      },
      "source": [
        "### Let's construct AlexNet in Keras!\n",
        "\n",
        "#### First let's load and prep our CIFAR10 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCtle7VjZQKe"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Loads the CIFAR dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Display our data shape/dimensions\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Now we one hot encode outputs\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "7BwPwHMwZQKf"
      },
      "source": [
        "### Now let's create our layers to replicate AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UmoJnnPZQKg"
      },
      "source": [
        "x_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt-rSe2WZQKg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FN4B1CmZQKh"
      },
      "source": [
        "l2_reg = 0\n",
        "\n",
        "# Initialize model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Conv Layer : CRP \n",
        "model.add(Conv2D(96, (11, 11), input_shape=x_train.shape[1:],\n",
        "    padding='same', kernel_regularizer=l2(l2_reg)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# 2nd Conv Layer \n",
        "model.add(Conv2D(256, (5, 5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# 3rd Conv Layer \n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# 4th Conv Layer \n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 5th Conv Layer \n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# 1st FC Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# 2nd FC Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# 3rd FC Layer\n",
        "model.add(Dense(num_classes))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o16Vllx0ZQKi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb4HJiCSZQKj"
      },
      "source": [
        "### Now let us train AlexNet on our CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQlS5zjOZQKj"
      },
      "source": [
        "# Training Parameters\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "model.save(\"CIFAR10_AlexNet_1_Epoch.h5\")\n",
        "\n",
        "# Evaluate the performance of our trained model\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wptcBGEZQKk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6o8Zhr2ZQKl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}